defaults:
  - hydra: default
  - _self_
  - model: rnn

save_dir: "/path/to/logs_wandb"
seed: 8

logger:
  _target_: lightning.pytorch.loggers.WandbLogger
  entity: entity
  project: project
  name: ${now:%Y-%m-%d}_${now:%H-%M-%S}
  save_dir: ${save_dir}
  offline: False
  tags: null


params_dataset:
  vocab_size: &vocab_size
    5 
  seq_len: &seq_len
    16
  lookahead: &p
    8
  datatype: &type
    'real'
  copymode: &mode
    "sin"    # {'linear, 'sin', 'parity'}

train_dataset:
  _target_: data_synthetic.SyntheticCopyDataset
  n_samples: 1000
  seq_len: *seq_len
  vocab_size: *vocab_size
  lookahead: *p
  datatype: *type
  copymode: *mode

val_dataset:
  _target_: data_synthetic.SyntheticCopyDataset
  n_samples: 2000
  seq_len: *seq_len
  vocab_size: *vocab_size
  lookahead: *p
  datatype: *type
  copymode: *mode

test_dataset:
  _target_: data_synthetic.SyntheticCopyDataset
  n_samples: 2000
  seq_len: *seq_len
  vocab_size: *vocab_size
  lookahead: *p
  datatype: *type
  copymode: *mode



datamodule:
  _target_: data_synthetic.SyntheticCopyDataModule
  batch_size: 128
  train_dataset: ${train_dataset}
  val_dataset: ${val_dataset}
  test_dataset: ${test_dataset}

trainer:
  max_epochs: 1000
  enable_progress_bar: True
  log_every_n_steps: 1
  limit_train_batches: 1.0
  accelerator: "cpu"

model: ${model}

callbacks:
  early_stopping:
    _target_: lightning.pytorch.callbacks.EarlyStopping
    monitor: val_loss
    patience: 400
    mode: min
    min_delta: 0
    verbose: True

task :
  _target_: task.CopyTaskRegression
  model: ${model}
  lr: 1e-3
